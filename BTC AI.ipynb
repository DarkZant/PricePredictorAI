{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import joblib as jb\n",
    "from binance.client import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>HLV1</th>\n",
       "      <th>V2</th>\n",
       "      <th>HLV2</th>\n",
       "      <th>V3</th>\n",
       "      <th>HLV3</th>\n",
       "      <th>V4</th>\n",
       "      <th>HLV4</th>\n",
       "      <th>V5</th>\n",
       "      <th>HLV5</th>\n",
       "      <th>...</th>\n",
       "      <th>V8</th>\n",
       "      <th>HLV8</th>\n",
       "      <th>V9</th>\n",
       "      <th>HLV9</th>\n",
       "      <th>V10</th>\n",
       "      <th>HLV10</th>\n",
       "      <th>V11</th>\n",
       "      <th>HLV11</th>\n",
       "      <th>V12</th>\n",
       "      <th>HLV12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110.410765</td>\n",
       "      <td>254.107649</td>\n",
       "      <td>12.247645</td>\n",
       "      <td>36.167997</td>\n",
       "      <td>-7.344125</td>\n",
       "      <td>23.995845</td>\n",
       "      <td>-4.982206</td>\n",
       "      <td>12.432432</td>\n",
       "      <td>-0.578822</td>\n",
       "      <td>7.532107</td>\n",
       "      <td>...</td>\n",
       "      <td>1.374443</td>\n",
       "      <td>8.730159</td>\n",
       "      <td>9.747160</td>\n",
       "      <td>23.299126</td>\n",
       "      <td>1.368948</td>\n",
       "      <td>18.132507</td>\n",
       "      <td>2.141680</td>\n",
       "      <td>13.623693</td>\n",
       "      <td>17.903226</td>\n",
       "      <td>27.402597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.247645</td>\n",
       "      <td>36.167997</td>\n",
       "      <td>-7.344125</td>\n",
       "      <td>23.995845</td>\n",
       "      <td>-4.982206</td>\n",
       "      <td>12.432432</td>\n",
       "      <td>-0.578822</td>\n",
       "      <td>7.532107</td>\n",
       "      <td>-17.294521</td>\n",
       "      <td>22.254576</td>\n",
       "      <td>...</td>\n",
       "      <td>9.747160</td>\n",
       "      <td>23.299126</td>\n",
       "      <td>1.368948</td>\n",
       "      <td>18.132507</td>\n",
       "      <td>2.141680</td>\n",
       "      <td>13.623693</td>\n",
       "      <td>17.903226</td>\n",
       "      <td>27.402597</td>\n",
       "      <td>-5.170999</td>\n",
       "      <td>12.860113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7.344125</td>\n",
       "      <td>23.995845</td>\n",
       "      <td>-4.982206</td>\n",
       "      <td>12.432432</td>\n",
       "      <td>-0.578822</td>\n",
       "      <td>7.532107</td>\n",
       "      <td>-17.294521</td>\n",
       "      <td>22.254576</td>\n",
       "      <td>11.516156</td>\n",
       "      <td>18.487744</td>\n",
       "      <td>...</td>\n",
       "      <td>1.368948</td>\n",
       "      <td>18.132507</td>\n",
       "      <td>2.141680</td>\n",
       "      <td>13.623693</td>\n",
       "      <td>17.903226</td>\n",
       "      <td>27.402597</td>\n",
       "      <td>-5.170999</td>\n",
       "      <td>12.860113</td>\n",
       "      <td>-5.968858</td>\n",
       "      <td>14.815990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.982206</td>\n",
       "      <td>12.432432</td>\n",
       "      <td>-0.578822</td>\n",
       "      <td>7.532107</td>\n",
       "      <td>-17.294521</td>\n",
       "      <td>22.254576</td>\n",
       "      <td>11.516156</td>\n",
       "      <td>18.487744</td>\n",
       "      <td>1.374443</td>\n",
       "      <td>8.730159</td>\n",
       "      <td>...</td>\n",
       "      <td>2.141680</td>\n",
       "      <td>13.623693</td>\n",
       "      <td>17.903226</td>\n",
       "      <td>27.402597</td>\n",
       "      <td>-5.170999</td>\n",
       "      <td>12.860113</td>\n",
       "      <td>-5.968858</td>\n",
       "      <td>14.815990</td>\n",
       "      <td>5.427783</td>\n",
       "      <td>16.016758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.578822</td>\n",
       "      <td>7.532107</td>\n",
       "      <td>-17.294521</td>\n",
       "      <td>22.254576</td>\n",
       "      <td>11.516156</td>\n",
       "      <td>18.487744</td>\n",
       "      <td>1.374443</td>\n",
       "      <td>8.730159</td>\n",
       "      <td>9.747160</td>\n",
       "      <td>23.299126</td>\n",
       "      <td>...</td>\n",
       "      <td>17.903226</td>\n",
       "      <td>27.402597</td>\n",
       "      <td>-5.170999</td>\n",
       "      <td>12.860113</td>\n",
       "      <td>-5.968858</td>\n",
       "      <td>14.815990</td>\n",
       "      <td>5.427783</td>\n",
       "      <td>16.016758</td>\n",
       "      <td>7.068063</td>\n",
       "      <td>12.031849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.709220</td>\n",
       "      <td>-0.985915</td>\n",
       "      <td>1.139601</td>\n",
       "      <td>0.426743</td>\n",
       "      <td>0.712251</td>\n",
       "      <td>-0.425532</td>\n",
       "      <td>0.712251</td>\n",
       "      <td>-0.142248</td>\n",
       "      <td>0.427350</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.282486</td>\n",
       "      <td>0.567376</td>\n",
       "      <td>0.424929</td>\n",
       "      <td>1.136364</td>\n",
       "      <td>2.401130</td>\n",
       "      <td>4.943503</td>\n",
       "      <td>1.103448</td>\n",
       "      <td>3.064067</td>\n",
       "      <td>0.136426</td>\n",
       "      <td>1.655172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>-0.985915</td>\n",
       "      <td>1.139601</td>\n",
       "      <td>0.426743</td>\n",
       "      <td>0.712251</td>\n",
       "      <td>-0.425532</td>\n",
       "      <td>0.712251</td>\n",
       "      <td>-0.142248</td>\n",
       "      <td>0.427350</td>\n",
       "      <td>0.711238</td>\n",
       "      <td>1.424501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424929</td>\n",
       "      <td>1.136364</td>\n",
       "      <td>2.401130</td>\n",
       "      <td>4.943503</td>\n",
       "      <td>1.103448</td>\n",
       "      <td>3.064067</td>\n",
       "      <td>0.136426</td>\n",
       "      <td>1.655172</td>\n",
       "      <td>-1.089918</td>\n",
       "      <td>1.241379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3400</th>\n",
       "      <td>0.426743</td>\n",
       "      <td>0.712251</td>\n",
       "      <td>-0.425532</td>\n",
       "      <td>0.712251</td>\n",
       "      <td>-0.142248</td>\n",
       "      <td>0.427350</td>\n",
       "      <td>0.711238</td>\n",
       "      <td>1.424501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.424328</td>\n",
       "      <td>...</td>\n",
       "      <td>2.401130</td>\n",
       "      <td>4.943503</td>\n",
       "      <td>1.103448</td>\n",
       "      <td>3.064067</td>\n",
       "      <td>0.136426</td>\n",
       "      <td>1.655172</td>\n",
       "      <td>-1.089918</td>\n",
       "      <td>1.241379</td>\n",
       "      <td>-0.826446</td>\n",
       "      <td>1.536313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401</th>\n",
       "      <td>-0.425532</td>\n",
       "      <td>0.712251</td>\n",
       "      <td>-0.142248</td>\n",
       "      <td>0.427350</td>\n",
       "      <td>0.711238</td>\n",
       "      <td>1.424501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.424328</td>\n",
       "      <td>-0.282486</td>\n",
       "      <td>0.567376</td>\n",
       "      <td>...</td>\n",
       "      <td>1.103448</td>\n",
       "      <td>3.064067</td>\n",
       "      <td>0.136426</td>\n",
       "      <td>1.655172</td>\n",
       "      <td>-1.089918</td>\n",
       "      <td>1.241379</td>\n",
       "      <td>-0.826446</td>\n",
       "      <td>1.536313</td>\n",
       "      <td>0.416089</td>\n",
       "      <td>0.835655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3402</th>\n",
       "      <td>-0.142248</td>\n",
       "      <td>0.427350</td>\n",
       "      <td>0.711238</td>\n",
       "      <td>1.424501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.424328</td>\n",
       "      <td>-0.282486</td>\n",
       "      <td>0.567376</td>\n",
       "      <td>0.424929</td>\n",
       "      <td>1.136364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136426</td>\n",
       "      <td>1.655172</td>\n",
       "      <td>-1.089918</td>\n",
       "      <td>1.241379</td>\n",
       "      <td>-0.826446</td>\n",
       "      <td>1.536313</td>\n",
       "      <td>0.416089</td>\n",
       "      <td>0.835655</td>\n",
       "      <td>-0.828729</td>\n",
       "      <td>0.974930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3403 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        HLV1         V2       HLV2         V3       HLV3  \\\n",
       "0     110.410765  254.107649  12.247645  36.167997  -7.344125  23.995845   \n",
       "1      12.247645   36.167997  -7.344125  23.995845  -4.982206  12.432432   \n",
       "2      -7.344125   23.995845  -4.982206  12.432432  -0.578822   7.532107   \n",
       "3      -4.982206   12.432432  -0.578822   7.532107 -17.294521  22.254576   \n",
       "4      -0.578822    7.532107 -17.294521  22.254576  11.516156  18.487744   \n",
       "...          ...         ...        ...        ...        ...        ...   \n",
       "3398    0.000000    0.709220  -0.985915   1.139601   0.426743   0.712251   \n",
       "3399   -0.985915    1.139601   0.426743   0.712251  -0.425532   0.712251   \n",
       "3400    0.426743    0.712251  -0.425532   0.712251  -0.142248   0.427350   \n",
       "3401   -0.425532    0.712251  -0.142248   0.427350   0.711238   1.424501   \n",
       "3402   -0.142248    0.427350   0.711238   1.424501   0.000000   0.424328   \n",
       "\n",
       "             V4       HLV4         V5       HLV5  ...         V8       HLV8  \\\n",
       "0     -4.982206  12.432432  -0.578822   7.532107  ...   1.374443   8.730159   \n",
       "1     -0.578822   7.532107 -17.294521  22.254576  ...   9.747160  23.299126   \n",
       "2    -17.294521  22.254576  11.516156  18.487744  ...   1.368948  18.132507   \n",
       "3     11.516156  18.487744   1.374443   8.730159  ...   2.141680  13.623693   \n",
       "4      1.374443   8.730159   9.747160  23.299126  ...  17.903226  27.402597   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "3398  -0.425532   0.712251  -0.142248   0.427350  ...  -0.282486   0.567376   \n",
       "3399  -0.142248   0.427350   0.711238   1.424501  ...   0.424929   1.136364   \n",
       "3400   0.711238   1.424501   0.000000   0.424328  ...   2.401130   4.943503   \n",
       "3401   0.000000   0.424328  -0.282486   0.567376  ...   1.103448   3.064067   \n",
       "3402  -0.282486   0.567376   0.424929   1.136364  ...   0.136426   1.655172   \n",
       "\n",
       "             V9       HLV9        V10      HLV10        V11      HLV11  \\\n",
       "0      9.747160  23.299126   1.368948  18.132507   2.141680  13.623693   \n",
       "1      1.368948  18.132507   2.141680  13.623693  17.903226  27.402597   \n",
       "2      2.141680  13.623693  17.903226  27.402597  -5.170999  12.860113   \n",
       "3     17.903226  27.402597  -5.170999  12.860113  -5.968858  14.815990   \n",
       "4     -5.170999  12.860113  -5.968858  14.815990   5.427783  16.016758   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "3398   0.424929   1.136364   2.401130   4.943503   1.103448   3.064067   \n",
       "3399   2.401130   4.943503   1.103448   3.064067   0.136426   1.655172   \n",
       "3400   1.103448   3.064067   0.136426   1.655172  -1.089918   1.241379   \n",
       "3401   0.136426   1.655172  -1.089918   1.241379  -0.826446   1.536313   \n",
       "3402  -1.089918   1.241379  -0.826446   1.536313   0.416089   0.835655   \n",
       "\n",
       "            V12      HLV12  \n",
       "0     17.903226  27.402597  \n",
       "1     -5.170999  12.860113  \n",
       "2     -5.968858  14.815990  \n",
       "3      5.427783  16.016758  \n",
       "4      7.068063  12.031849  \n",
       "...         ...        ...  \n",
       "3398   0.136426   1.655172  \n",
       "3399  -1.089918   1.241379  \n",
       "3400  -0.826446   1.536313  \n",
       "3401   0.416089   0.835655  \n",
       "3402  -0.828729   0.974930  \n",
       "\n",
       "[3403 rows x 24 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import and split data \n",
    "data = pd.read_csv('1HVHLV.csv', sep = ',')\n",
    "X = data.drop('Final', axis = 1)\n",
    "y = data['Final']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.21033721, -0.15509184, -0.18234929, ..., -0.25536786,\n",
       "         0.17870814, -0.41698117],\n",
       "       [ 0.16478207, -0.37732318, -0.22409254, ..., -0.60821415,\n",
       "        -0.07606494, -0.51320562],\n",
       "       [-0.78715643,  0.23625314, -0.24402962, ..., -0.12571266,\n",
       "        -0.6224693 ,  0.47631914],\n",
       "       ...,\n",
       "       [-0.6712532 ,  0.12824024, -0.69143551, ..., -0.4444605 ,\n",
       "         0.31925609, -0.43657134],\n",
       "       [ 0.23147279, -0.2536386 , -0.31077069, ..., -0.45396477,\n",
       "        -0.03046471, -0.4433493 ],\n",
       "       [-0.03424825, -0.39530237, -0.13768985, ..., -0.51168126,\n",
       "        -0.18443735, -0.54290858]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prepare data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.90      0.94       446\n",
      "        True       0.90      0.98      0.94       403\n",
      "\n",
      "    accuracy                           0.94       849\n",
      "   macro avg       0.94      0.94      0.94       849\n",
      "weighted avg       0.94      0.94      0.94       849\n",
      "\n",
      "0.9375736160188457\n"
     ]
    }
   ],
   "source": [
    "mlpc = MLPClassifier(hidden_layer_sizes = (12,12), max_iter = 2000)\n",
    "param_grid = { 'activation' : ['identity', 'logistic', 'tanh', 'relu'],\n",
    "                'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "                'learning_rate' : ['constant', 'invscaling', 'adaptive']}\n",
    "    \n",
    "grid = GridSearchCV(mlpc, param_grid, cv = 10, verbose = 3,n_jobs=-1)\n",
    "grid.fit(X_train,y_train)\n",
    "print(grid.best_params_)\n",
    "grid_predictions = grid.predict(X_test) \n",
    "print(classification_report(y_test, grid_predictions, zero_division = 0)) \n",
    "print(accuracy_score(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.55      1.00      0.71       464\n",
      "        True       0.00      0.00      0.00       385\n",
      "\n",
      "    accuracy                           0.55       849\n",
      "   macro avg       0.27      0.50      0.35       849\n",
      "weighted avg       0.30      0.55      0.39       849\n",
      "\n",
      "0.5465253239104829\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15)\n",
    "clf = svm.SVC(C = 1, gamma = 'auto', kernel = 'sigmoid')\n",
    "# param_grid2 = {'C': [0.1, 1, 10, 100],  \n",
    "#               'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "#               'gamma':['scale', 'auto'],\n",
    "#               'kernel': ['linear','sigmoid','rbf','poly']}     \n",
    "# grid2 = GridSearchCV(clf, param_grid2, verbose = 3,n_jobs=-1)\n",
    "# grid2.fit(X_train,y_train)\n",
    "clf.fit(X_train,y_train)\n",
    "# print(grid2.best_params_)\n",
    "# grid_predictions2 = grid2.predict(X_test) \n",
    "clf_predictions = clf.predict(X_test)\n",
    "print(classification_report(y_test, clf_predictions, zero_division = 0)) \n",
    "print(accuracy_score(y_test, clf_predictions))\n",
    "# print(classification_report(y_test, grid_predictions2)) \n",
    "# print(accuracy_score(y_test, grid_predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.56      1.00      0.72       477\n",
      "        True       0.00      0.00      0.00       372\n",
      "\n",
      "    accuracy                           0.56       849\n",
      "   macro avg       0.28      0.50      0.36       849\n",
      "weighted avg       0.32      0.56      0.40       849\n",
      "\n",
      "[[477   0]\n",
      " [372   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5618374558303887"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15)\n",
    "# sc = StandardScaler()\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)\n",
    "ai = BernoulliNB(alpha=1.0, binarize =0.0, class_prior = None, fit_prior = True)\n",
    "ai.fit(X_train,y_train)\n",
    "pred_ai = ai.predict(X_test) \n",
    "print(classification_report(y_test, pred_ai, zero_division = 0))\n",
    "print(confusion_matrix(y_test, pred_ai))\n",
    "score = accuracy_score(y_test, pred_ai) \n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "{'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.57      0.32      0.41       255\n",
      "        True       0.53      0.76      0.62       256\n",
      "\n",
      "    accuracy                           0.54       511\n",
      "   macro avg       0.55      0.54      0.52       511\n",
      "weighted avg       0.55      0.54      0.52       511\n",
      "\n",
      "0.5401174168297456\n"
     ]
    }
   ],
   "source": [
    "bestscore = 0\n",
    "score = 0\n",
    "#for i in range(15):\n",
    "ai = MLPClassifier(hidden_layer_sizes = (250,250,250,250,250,250), max_iter = 2500, activation = 'tanh', solver = 'adam', learning_rate = 'constant', alpha = 0.0001)\n",
    "ai.fit(X_train,y_train)\n",
    "pred_ai = ai.predict(X_test)   \n",
    "score = accuracy_score(y_test, pred_ai) \n",
    "# pred_ai2 = ai.predict(X2_test)\n",
    "# score2 = accuracy_score(y2_test, pred_ai2)\n",
    "#     #print(f'Score #{i}: {score}')\n",
    "#     #if bestscore < score:       \n",
    "#       #  bestscore = score\n",
    "#       #  best = ai\n",
    "#        # print(f'New best score: {bestscore}!')\n",
    "print(classification_report(y_test, pred_ai, zero_division = 0)) \n",
    "print(score)\n",
    "# print()\n",
    "# print(classification_report(y2_test, pred_ai2, zero_division = 0))\n",
    "# score2\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_jobs=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLPClassifier(hidden_layer_sizes = (200,200,200), max_iter = 2500, activation = 'tanh', solver = 'adam', learning_rate = 'constant', alpha = 0.0001)\n",
    "svm.SVC(C = 1, gamma = 'auto', kernel = 'rbf')\n",
    "Pipeline(steps=[('linearsvc',LinearSVC(C=5.0,class_weight = None, dual = False,fit_intercept = True,intercept_scaling = 1, loss ='squared_hinge',\n",
    "                 max_iter = 1000, multi_class = 'ovr', penalty = 'l2', verbose = 0))])\n",
    "BernoulliNB(alpha=1.0, binarize =0.0, class_prior = None, fit_prior = True)\n",
    "KNeighborsClassifier(algorithm = 'auto', leaf_size = 30, metric = 'minkowski', metric_params = None, n_jobs = 1, n_neighbors = 5, p=2, weights = 'uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.57      0.32      0.41       255\n",
      "        True       0.53      0.76      0.62       256\n",
      "\n",
      "    accuracy                           0.54       511\n",
      "   macro avg       0.55      0.54      0.52       511\n",
      "weighted avg       0.55      0.54      0.52       511\n",
      "\n",
      "[[ 81 174]\n",
      " [ 61 195]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5401174168297456"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ai = grid\n",
    "pred_bmlpc = best_ai.predict(X_test)\n",
    "print(classification_report(y_test, pred_bmlpc))\n",
    "print(confusion_matrix(y_test, pred_bmlpc))\n",
    "score = accuracy_score(y_test, pred_bmlpc)\n",
    "score\n",
    "#jb.dump(best_mlpc,'btc.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PricePredictorAI.joblib']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jb.dump(best_ai,'PricePredictorAI.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jb.dump(bsc,'svcscaler.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
